# -*- coding: utf-8 -*-
"""customer_segmentation.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1AnySwQUQroB__L-QebhwxPS7g3AZeJR3

**Step 1: Load and Explore the Dataset**

> Import the dataset and check for missing values and duplicates.
"""

import pandas as pd

# Load dataset
df = pd.read_csv("OnlineRetail.csv", encoding="ISO-8859-1")

# Display first few rows
print(df.head())

# Check for missing values
print(df.isnull().sum())

"""> Drop missing CustomerID rows (since they are essential for segmentation)."""

df.dropna(subset=['CustomerID'], inplace=True)

"""**Step 2: Data Cleaning**

> 1. Convert InvoiceDate to DateTime format
"""

df['InvoiceDate'] = pd.to_datetime(df['InvoiceDate'])

"""> 2.Remove negative Quantity values (as they indicate returns).

"""

df = df[df['Quantity'] > 0]

"""> 3.Create a TotalPrice column (Total revenue per transaction)."""

df['TotalPrice'] = df['Quantity'] * df['UnitPrice']

"""**Step 3: Feature Engineering (RFM Analysis)**

Since the dataset doesn’t have predefined customer segments, we need to extract meaningful features:

Recency – Days since the last purchase.
Frequency – Number of unique transactions per customer.
Monetary – Total spending per customer.
"""

# Get the latest date in the dataset
latest_date = df['InvoiceDate'].max()

# Compute RFM values per CustomerID
rfm = df.groupby('CustomerID').agg({
    'InvoiceDate': lambda x: (latest_date - x.max()).days,  # Recency
    'InvoiceNo': 'nunique',  # Frequency (unique transactions)
    'TotalPrice': 'sum'  # Monetary (total spending)
}).reset_index()

# Rename columns
rfm.columns = ['CustomerID', 'Recency', 'Frequency', 'Monetary']

# Display the first few rows
print(rfm.head())



"""**Step 4: Data Preprocessing for Clustering**

> 1.Remove outliers (Optional but recommended).
"""

# Remove extreme outliers using quantiles
rfm = rfm[(rfm['Monetary'] < rfm['Monetary'].quantile(0.99))]  # Remove top 1% spenders

"""> 2.Normalize the data (Required for K-Means)."""

from sklearn.preprocessing import StandardScaler

scaler = StandardScaler()
rfm_scaled = scaler.fit_transform(rfm[['Recency', 'Frequency', 'Monetary']])

"""**Step 5: Apply PCA for Dimensionality Reduction**"""

#Since RFM has three features, we reduce it to two principal components for better visualization.
from sklearn.decomposition import PCA

pca = PCA(n_components=2)
rfm_pca = pca.fit_transform(rfm_scaled)

# Convert PCA results into a DataFrame
rfm_pca_df = pd.DataFrame(rfm_pca, columns=['PC1', 'PC2'])
rfm_pca_df['CustomerID'] = rfm['CustomerID']

"""**Step 6: Determine the Optimal Number of Clusters (K)**

> A. Elbow Method
"""

import matplotlib.pyplot as plt
from sklearn.cluster import KMeans

inertia = []
k_range = range(1, 11)

for k in k_range:
    kmeans = KMeans(n_clusters=k, random_state=42)
    kmeans.fit(rfm_scaled)
    inertia.append(kmeans.inertia_)

# Plot the elbow curve
plt.figure(figsize=(8, 5))
plt.plot(k_range, inertia, marker='o')
plt.xlabel('Number of Clusters')
plt.ylabel('Inertia')
plt.title('Elbow Method for Optimal K')
plt.show()

"""> B. Silhouette Score"""

from sklearn.metrics import silhouette_score

for k in range(2, 11):
    kmeans = KMeans(n_clusters=k, random_state=42)
    labels = kmeans.fit_predict(rfm_scaled)
    score = silhouette_score(rfm_scaled, labels)
    print(f'K={k}, Silhouette Score={score}')

"""**Step 7: Apply K-Means Clustering**"""

optimal_k = 3  # Example: Choose based on the elbow method
kmeans = KMeans(n_clusters=optimal_k, random_state=42)
rfm['Cluster'] = kmeans.fit_predict(rfm_scaled)

"""**Step 8: Visualize the Customer Segments**

> A. PCA Scatter Plot
"""

import seaborn as sns

rfm_pca_df['Cluster'] = rfm['Cluster']

plt.figure(figsize=(10, 6))
sns.scatterplot(x='PC1', y='PC2', hue='Cluster', data=rfm_pca_df, palette='viridis')
plt.title('Customer Segments using PCA')
plt.show()

"""> B. Boxplot for Monetary Value per Cluster"""

plt.figure(figsize=(10, 6))
sns.boxplot(x='Cluster', y='Monetary', data=rfm)
plt.title('Customer Segments by Monetary Value')
plt.show()

"""**Step 9: Interpret and Apply Insights**

> High-Value Customers (Cluster X): Frequent shoppers with high spending (Target with loyalty programs).

> Occasional Buyers (Cluster Y): Moderate frequency and spending (Target with promotions).

> Infrequent Buyers (Cluster Z): Rare purchases, low spending (Re-engagement strategies).

**Step 10: Save the Model for Future Use**
"""

import joblib

joblib.dump(kmeans, 'customer_segmentation.pkl')